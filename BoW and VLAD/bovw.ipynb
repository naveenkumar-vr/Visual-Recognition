{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# !pip install opencv-contrib-python==3.4.2.17\n",
    "import cv2\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.model_selection import StratifiedKFold   \n",
    "import keras\n",
    "from keras.datasets import cifar10\n",
    "from scipy.cluster.vq import *\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import sklearn.metrics as metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def desSIFT(image):\n",
    "    sift = cv2.xfeatures2d.SIFT_create()\n",
    "    kp, des = sift.detectAndCompute(image,None)\n",
    "    #draw keypoints\n",
    "    #import matplotlib.pyplot as plt\t\t\n",
    "    #img2 = cv2.drawKeypoints(img,kp,None,(255,0,0),4)\n",
    "    #plt.imshow(img2),plt.show()\n",
    "    return kp,des\n",
    "\n",
    "def describeSURF( image):\n",
    "    surf = cv2.xfeatures2d.SURF_create()\n",
    "    # it is better to have this value between 300 and 500\n",
    "#     surf.setHessianThreshold(400)\n",
    "    kp, des = surf.detectAndCompute(image,None)\n",
    "    return kp,des\n",
    "\n",
    "\n",
    "def getDescriptors(images, labels_g) : \n",
    "    descriptors = []\n",
    "    labels = []\n",
    "    count = 0\n",
    "    \n",
    "    print (images.shape)\n",
    "    for image in images : \n",
    "        print (image.shape)\n",
    "        #Converting the image into grayscale         \n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY) \n",
    "        #Re-sizing the image\n",
    "        image = cv2.resize(image, (150, 150), interpolation=cv2.INTER_AREA)\n",
    "        kp, des = describeSURF(image)\n",
    "        \n",
    "        if des is not None : \n",
    "            print (des.shape)\n",
    "            descriptors.append(des)\n",
    "            labels.append(int(labels_g[count]))\n",
    "        count += 1\n",
    "            \n",
    "    \n",
    "    print (len(labels))\n",
    "    \n",
    "    descriptorsFin = descriptors[0]\n",
    "    \n",
    "    for descriptor in descriptors[1:]:\n",
    "        if descriptor is not None:\n",
    "            descriptorsFin = np.vstack((descriptorsFin, descriptor))\n",
    "    \n",
    "        \n",
    "    return descriptorsFin, descriptors, labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sift_des, descriptors, sift_labels = getDescriptors(np.concatenate((x_train, x_test), axis = 0), np.concatenate((y_train, y_test)))\n",
    "\n",
    "k = 50\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# k means with k clusters on sift descriptors\n",
    "voc,  variance = kmeans((sift_des), k, 1)\n",
    "print (np.concatenate((y_train, y_test)).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (len(sift_labels))\n",
    "print (len(sift_des))\n",
    "\n",
    "# Constructing a histogram of k clusters and number of images having those clusters\n",
    "imageFeatures = np.zeros((len(sift_labels), k), \"float32\")\n",
    "for i in range(len(sift_labels)):\n",
    "    words, distance = vq(descriptors[i],voc)\n",
    "    for w in words:\n",
    "        imageFeatures[i][w] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalizing the histogram(Image Features)\n",
    "stdSlr = StandardScaler().fit(imageFeatures)\n",
    "imageFeatures = stdSlr.transform(imageFeatures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the Image Features into test and train\n",
    "X_train, X_test, y_train, y_test = train_test_split(imageFeatures, sift_labels, test_size=0.1, random_state=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training the train data using knn\n",
    "clf = cv2.ml.KNearest_create()\n",
    "clf.train(X_train, cv2.ml.ROW_SAMPLE, np.asarray(y_train, dtype=np.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting the test values\n",
    "ret, results, neighbours ,dist = clf.findNearest(X_test, k=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pred_label = []\n",
    "for var in results:\n",
    "    label = var\n",
    "    pred_label.append(int(label))\n",
    "\n",
    "print (y_test)\n",
    "print (pred_label)\n",
    "    \n",
    "# Measuring the accuracies\n",
    "metrics.accuracy_score(y_test, pred_label)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
